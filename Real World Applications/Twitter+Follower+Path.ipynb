{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12, 422, 53, 52, 107, 20, 23, 274, 34\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "sc = SparkContext(conf= SparkConf().setAppName(\"App\").setMaster('local'))\n",
    "\n",
    "# line input (from /data/twitter/twitter_sample_small.txt):\n",
    "#    v1<tab>v2\n",
    "# output:\n",
    "#    (v1, v2)\n",
    "\n",
    "def parse_edge(s):\n",
    "    user, follower = s.split(\"\\t\")\n",
    "    return (int(user), int(follower))\n",
    "\n",
    "# input (result of join of distances to edges)\n",
    "#    distances: (v1, (d1, p1))\n",
    "#    edges: (v1, v2)\n",
    "#    result: (v1, ((d1, p1), v2))\n",
    "# output\n",
    "#    (v2, (d1 + 1, p1 + v1))\n",
    "\n",
    "def step(item):\n",
    "    prev_v, prev_d, next_v,path = item[0], item[1][0][0], item[1][1], item[1][0][1]\n",
    "    new_path = list(path)\n",
    "    new_path.append(prev_v)\n",
    "    return (next_v, (prev_d + 1, tuple(new_path)))\n",
    "\n",
    "\n",
    "# input (result of full outer join of distances and candidates (result of step function))\n",
    "#    distances: (v, (d1, p1))\n",
    "#    candidates: (v, (d2, p2))\n",
    "#    result: (v, ((d1, p1),(d2, p2) ))\n",
    "# output (v, (d, p))\n",
    "\n",
    "def complete(item):\n",
    "    v = item[0]\n",
    "    old_d = item[1][0][0] if item[1][0] is not None else None\n",
    "    new_d = None\n",
    "    path = ()\n",
    "    if item[1][1] is not None:\n",
    "        new_d = item[1][1][0]\n",
    "        path = item[1][1][1]\n",
    "    return (v, (old_d if old_d is not None else new_d, path))\n",
    "\n",
    "\n",
    "n = 200  # number of partitions\n",
    "edges = sc.textFile(\"/data/twitter/twitter_sample_small.txt\") \\\n",
    "        .map(parse_edge) \\\n",
    "        .cache()\n",
    "forward_edges = edges.map(lambda e: (e[1], e[0])) \\\n",
    "        .partitionBy(n) \\\n",
    "        .persist()\n",
    "\n",
    "start = 12\n",
    "end = 34\n",
    "d = 0\n",
    "path = ()\n",
    "path_result = \"Path not found\"\n",
    "\n",
    "\n",
    "distances = sc.parallelize([ (start, (d, path)) ]) \\\n",
    "        .partitionBy(n)\n",
    "\n",
    "while True:\n",
    "    candidates = distances.join(forward_edges, n) \\\n",
    "              .map(step) \\\n",
    "              .reduceByKey(lambda v1, v2: v1 if v1[0] < v2[0] else v2)\n",
    "            \n",
    "    found = distances.filter(lambda c: c[0] == end)   \n",
    "    if (found.count() > 0):\n",
    "        p = list(found.take(1)[0][1][1]);\n",
    "        p.append(end)\n",
    "        path_result = '%s' % ','.join(map(str, p))\n",
    "        break;\n",
    "        \n",
    "    new_distances = distances.fullOuterJoin(candidates, n) \\\n",
    "            .map(complete, True) \\\n",
    "            .persist()\n",
    "\n",
    "    count = new_distances.filter(lambda i: i[1][0] == d + 1).count()\n",
    "    if count > 0:\n",
    "        d += 1\n",
    "        distances = new_distances\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print path_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
